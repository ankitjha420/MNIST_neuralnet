{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST DATASET : MULTI LAYER PERCEPTRON VS COVNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULTI LAYER PERCEPTRON (dense neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''IMPORTING LIBRARIES'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''IMPORTING MNIST DATA FROM KERAS'''\n",
    "tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "'''IMPORTING MNIST DATA FROM KERAS'''\n",
    "tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "(a_train, b_train), (a_test, b_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''NAORMALIZING IMAGE DATA BY SUBTRACTING WITH MEAN AND DDIVIDING BY STD DEV'''\n",
    "x_train = x_train - np.mean(x_train)\n",
    "x_test = x_test - np.mean(x_test)\n",
    "\n",
    "x_train = x_train / np.std(x_train)\n",
    "x_test = x_test / np.std(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 784)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''WE CAN USE KERAS FLATTEN LAYER TO TURN 2D VECTOR INTO 1D'''\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.output_shape\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Y COLUMN SHOULD BE CATEGORICAL'''\n",
    "\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(28,28)))\n",
    "model.add(layers.Dense(90, activation = 'relu'))\n",
    "model.add(layers.Dense(30, activation = 'relu'))\n",
    "model.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 3s 4ms/step - loss: 0.3186 - accuracy: 0.9036\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1397 - accuracy: 0.9579\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1024 - accuracy: 0.9696\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0804 - accuracy: 0.9753\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0661 - accuracy: 0.9787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2641577d518>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1017 - accuracy: 0.9714\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A VALIDATION SET WITH 15K SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 28, 28) (45000, 10)\n",
      "(15000, 28, 28) (15000, 10)\n",
      "(10000, 28, 28) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "'''IMPORTING MNIST DATA FROM KERAS'''\n",
    "tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "'''NAORMALIZING IMAGE DATA BY SUBTRACTING WITH MEAN AND DDIVIDING BY STD DEV'''\n",
    "x_train = x_train - np.mean(x_train)\n",
    "x_test = x_test - np.mean(x_test)\n",
    "\n",
    "x_train = x_train / np.std(x_train)\n",
    "x_test = x_test / np.std(x_test)\n",
    "\n",
    "'''Y COLUMN SHOULD BE CATEGORICAL'''\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "'''DEFINING X_VAL AND Y_VAL'''\n",
    "x_val = x_train[-15000:]\n",
    "y_val = y_train[-15000:]\n",
    "x_train = x_train[:-15000]\n",
    "y_train = y_train[:-15000]\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUNNING PREVIOUSLY MADE MODEL WITH VALIDATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(28,28)))\n",
    "model.add(layers.Dense(90, activation = 'relu'))\n",
    "model.add(layers.Dense(30, activation = 'relu'))\n",
    "model.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "352/352 [==============================] - 2s 4ms/step - loss: 0.3324 - accuracy: 0.8997 - val_loss: 0.1821 - val_accuracy: 0.9449\n",
      "Epoch 2/6\n",
      "352/352 [==============================] - 1s 4ms/step - loss: 0.1434 - accuracy: 0.9562 - val_loss: 0.1422 - val_accuracy: 0.9577\n",
      "Epoch 3/6\n",
      "352/352 [==============================] - 1s 4ms/step - loss: 0.1015 - accuracy: 0.9691 - val_loss: 0.1369 - val_accuracy: 0.9579\n",
      "Epoch 4/6\n",
      "352/352 [==============================] - 1s 4ms/step - loss: 0.0783 - accuracy: 0.9756 - val_loss: 0.1104 - val_accuracy: 0.9681\n",
      "Epoch 5/6\n",
      "352/352 [==============================] - 1s 4ms/step - loss: 0.0621 - accuracy: 0.9803 - val_loss: 0.1062 - val_accuracy: 0.9681\n",
      "Epoch 6/6\n",
      "352/352 [==============================] - 1s 4ms/step - loss: 0.0511 - accuracy: 0.9842 - val_loss: 0.1213 - val_accuracy: 0.9655\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                   batch_size=128,\n",
    "                   epochs=6, \n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1117 - accuracy: 0.9686\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9685999751091003"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUR MLP NETWORK BEGINS TO OVERFIT THE DATA AFTER EPOCH 6, SO THAT SHALL BE OUR LAST EPOCH\n",
    "\n",
    "### MODEL ACCURACY = 96.85%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A SIMPLE CONVOLUTIONAL NETWORK FOR THE SAME DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000, 10)\n",
      "(10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "'''IMPORTING MNIST DATA FROM KERAS'''\n",
    "tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "'''Y COLUMN SHOULD BE CATEGORICAL'''\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "x_train = x_train.reshape((60000, 28, 28, 1))\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.reshape((10000, 28, 28, 1))\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(90, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 90)                51930     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                910       \n",
      "=================================================================\n",
      "Total params: 108,584\n",
      "Trainable params: 108,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', \n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1944 - accuracy: 0.9378 - val_loss: 0.0768 - val_accuracy: 0.9783\n",
      "Epoch 2/5\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.0517 - accuracy: 0.9843 - val_loss: 0.0726 - val_accuracy: 0.9797\n",
      "Epoch 3/5\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.0355 - accuracy: 0.9887 - val_loss: 0.0493 - val_accuracy: 0.9865\n",
      "Epoch 4/5\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.0261 - accuracy: 0.9919 - val_loss: 0.0437 - val_accuracy: 0.9870\n",
      "Epoch 5/5\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.0205 - accuracy: 0.9940 - val_loss: 0.0515 - val_accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                   batch_size = 64,\n",
    "                   epochs = 5,\n",
    "                   validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0517 - accuracy: 0.9916: 0s - loss: 0.0512 - accuracy: 0.\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.991599977016449"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.051691651344299316"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE CONVOLUTIONAL MODEL GIVES AN ACCURACY OF 99.15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
